{
   "params": {
      "model": {
         "d_qk": 8,
         "qk_type": "data+PE",
         "n_layers_qk": 1,
         "n_layers": 1,
         "bias": true,
         "activation": "relu",
         "layernorm": false,
         "d_out": 1,
         "init_random": true,
         "weight_type": "gaussian",
         "dropout_p": 0.001,
         "attention_type": "linear"
      },
      "data": {
         "batch_size": 1,
         "impute": "none"
      },
      "training": {
         "n_epochs": 150,
         "lr": 0.001,
         "loss": "CE",
         "grad_step_every": 8
      }
   }
}